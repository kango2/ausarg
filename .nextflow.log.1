Nov-21 14:37:30.228 [main] DEBUG nextflow.cli.Launcher - $> nextflow /g/data/xl04/ka6418/github/ausarg/nextflow/non-experimental/genejigsaw.nf -config /g/data/xl04/ka6418/github/ausarg/nextflow/non-experimental/genejigsaw.config --topfolder /g/data/xl04/ka6418/github/ausarg/nextflow/outtest
Nov-21 14:37:30.339 [main] INFO  nextflow.cli.CmdRun - N E X T F L O W  ~  version 23.04.3
Nov-21 14:37:30.355 [main] DEBUG nextflow.plugin.PluginsFacade - Setting up plugin manager > mode=prod; embedded=false; plugins-dir=/home/150/ka6418/.nextflow/plugins; core-plugins: nf-amazon@1.16.2,nf-azure@1.0.1,nf-codecommit@0.1.4,nf-console@1.0.5,nf-ga4gh@1.0.5,nf-google@1.7.3,nf-tower@1.5.12,nf-wave@0.8.4
Nov-21 14:37:30.364 [main] INFO  org.pf4j.DefaultPluginStatusProvider - Enabled plugins: []
Nov-21 14:37:30.365 [main] INFO  org.pf4j.DefaultPluginStatusProvider - Disabled plugins: []
Nov-21 14:37:30.367 [main] INFO  org.pf4j.DefaultPluginManager - PF4J version 3.4.1 in 'deployment' mode
Nov-21 14:37:30.376 [main] INFO  org.pf4j.AbstractPluginManager - No plugins
Nov-21 14:37:30.407 [main] DEBUG nextflow.config.ConfigBuilder - User config file: /g/data/xl04/ka6418/github/ausarg/nextflow/non-experimental/genejigsaw.config
Nov-21 14:37:30.408 [main] DEBUG nextflow.config.ConfigBuilder - Parsing config file: /g/data/xl04/ka6418/github/ausarg/nextflow/non-experimental/genejigsaw.config
Nov-21 14:37:30.426 [main] DEBUG nextflow.config.ConfigBuilder - Applying config profile: `standard`
Nov-21 14:37:30.999 [main] DEBUG nextflow.cli.CmdRun - Applied DSL=2 by global default
Nov-21 14:37:31.005 [main] INFO  nextflow.cli.CmdRun - Launching `/g/data/xl04/ka6418/github/ausarg/nextflow/non-experimental/genejigsaw.nf` [gloomy_einstein] DSL2 - revision: a20728ed04
Nov-21 14:37:31.006 [main] WARN  nextflow.plugin.PluginsFacade - Nextflow self-contained distribution allows only core plugins -- User config plugins will be ignored: nf-sqldb
Nov-21 14:37:31.019 [main] DEBUG nextflow.secret.LocalSecretsProvider - Secrets store: /home/150/ka6418/.nextflow/secrets/store.json
Nov-21 14:37:31.022 [main] DEBUG nextflow.secret.SecretsLoader - Discovered secrets providers: [nextflow.secret.LocalSecretsProvider@20eaeaf8] - activable => nextflow.secret.LocalSecretsProvider@20eaeaf8
Nov-21 14:37:31.072 [main] DEBUG nextflow.Session - Session UUID: ea2064ff-1848-47f5-a0bf-7fc68bd6300b
Nov-21 14:37:31.073 [main] DEBUG nextflow.Session - Run name: gloomy_einstein
Nov-21 14:37:31.073 [main] DEBUG nextflow.Session - Executor pool size: 48
Nov-21 14:37:31.105 [main] DEBUG nextflow.util.ThreadPoolBuilder - Creating thread pool 'FileTransfer' minSize=10; maxSize=144; workQueue=LinkedBlockingQueue[10000]; allowCoreThreadTimeout=false
Nov-21 14:37:31.368 [main] DEBUG nextflow.cli.CmdRun - 
  Version: 23.04.3 build 5876
  Created: 18-09-2023 03:27 UTC (13:27 GMT+10:00)
  System: Linux 4.18.0-477.27.1.el8.nci.x86_64
  Runtime: Groovy 3.0.16 on OpenJDK 64-Bit Server VM 17.0.2+8-86
  Encoding: UTF-8 (UTF-8)
  Process: 3403827@gadi-login-06.gadi.nci.org.au [10.6.152.6]
  CPUs: 48 - Mem: 4 GB (159.9 MB) - Swap: 16 GB (9.2 GB)
Nov-21 14:37:31.500 [main] DEBUG nextflow.Session - Work-dir: /g/data/xl04/ka6418/github/ausarg/work [lustre]
Nov-21 14:37:31.500 [main] DEBUG nextflow.Session - Script base path does not exist or is not a directory: /g/data/xl04/ka6418/github/ausarg/nextflow/non-experimental/bin
Nov-21 14:37:31.536 [main] DEBUG nextflow.executor.ExecutorFactory - Extension executors providers=[GoogleLifeSciencesExecutor, AwsBatchExecutor, GoogleBatchExecutor]
Nov-21 14:37:31.545 [main] DEBUG nextflow.Session - Observer factory: DefaultObserverFactory
Nov-21 14:37:31.547 [main] DEBUG nextflow.Session - Observer factory: TowerFactory
Nov-21 14:37:31.563 [main] DEBUG nextflow.cache.CacheFactory - Using Nextflow cache factory: nextflow.cache.DefaultCacheFactory
Nov-21 14:37:31.570 [main] DEBUG nextflow.util.CustomThreadPool - Creating default thread pool > poolSize: 49; maxThreads: 1000
Nov-21 14:37:31.670 [main] DEBUG nextflow.Session - Session start
Nov-21 14:37:31.902 [main] DEBUG nextflow.script.ScriptRunner - > Launching execution
Nov-21 14:37:31.912 [main] DEBUG nextflow.plugin.PluginUpdater - Installing plugin nf-sqldb version: latest
Nov-21 14:37:32.999 [main] INFO  org.pf4j.AbstractPluginManager - Plugin 'nf-sqldb@0.5.0' resolved
Nov-21 14:37:33.000 [main] INFO  org.pf4j.AbstractPluginManager - Start plugin 'nf-sqldb@0.5.0'
Nov-21 14:37:33.017 [main] DEBUG nextflow.plugin.BasePlugin - Plugin started nf-sqldb@0.5.0
Nov-21 14:37:33.018 [main] DEBUG nextflow.script.IncludeDef - Loading included plugin extensions with names: [fromQuery:fromQuery]; plugin Id: nf-sqldb
Nov-21 14:37:33.301 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: pbspro
Nov-21 14:37:33.301 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'pbspro'
Nov-21 14:37:33.308 [main] DEBUG nextflow.executor.Executor - [warm up] executor > pbspro
Nov-21 14:37:33.313 [main] DEBUG n.processor.TaskPollingMonitor - Creating task monitor for executor 'pbspro' > capacity: 100; pollInterval: 5s; dumpInterval: 5m 
Nov-21 14:37:33.316 [main] DEBUG n.executor.AbstractGridExecutor - Creating executor 'pbspro' > queue-stat-interval: 1m
Nov-21 14:37:33.373 [main] DEBUG nextflow.executor.ExecutorFactory - << taskConfig executor: pbspro
Nov-21 14:37:33.374 [main] DEBUG nextflow.executor.ExecutorFactory - >> processorType: 'pbspro'
Nov-21 14:37:33.376 [main] DEBUG nextflow.Session - Workflow process names [dsl2]: longread_qc, shortread_qc
Nov-21 14:37:33.377 [main] DEBUG nextflow.Session - Igniting dataflow network (4)
Nov-21 14:37:33.377 [main] DEBUG nextflow.sql.QueryHandler - Creating SQL connection: SqlDataSource[url=jdbc:sqlite:/g/data/xl04/ka6418/github/ausarg/nextflow/pipeline/inputdb.db; driver=org.sqlite.JDBC; user=sa; password=null]
Nov-21 14:37:34.652 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > longread_qc
Nov-21 14:37:34.653 [main] DEBUG nextflow.sql.QueryHandler - Creating SQL connection: SqlDataSource[url=jdbc:sqlite:/g/data/xl04/ka6418/github/ausarg/nextflow/pipeline/inputdb.db; driver=org.sqlite.JDBC; user=sa; password=null]
Nov-21 14:37:34.654 [main] DEBUG nextflow.processor.TaskProcessor - Starting process > shortread_qc
Nov-21 14:37:34.654 [main] DEBUG nextflow.script.ScriptRunner - > Awaiting termination 
Nov-21 14:37:34.654 [main] DEBUG nextflow.Session - Session await
Nov-21 14:37:35.006 [Task submitter] WARN  nextflow.executor.PbsProExecutor - cpus and memory directives are ignored when clusterOptions contains -l option
tip: clusterOptions = { "-l ncpus=${task.cpus},mem=${task.memory.toGiga()}G..." }
Nov-21 14:37:38.283 [Task submitter] DEBUG nextflow.executor.GridTaskHandler - [PBSPRO] submitted process shortread_qc (1) > jobId: 101965080.gadi-pbs; workDir: /g/data/xl04/ka6418/github/ausarg/work/58/9654eb751d4a736a214e5e22524c2e
Nov-21 14:37:38.283 [Task submitter] INFO  nextflow.Session - [58/9654eb] Submitted process > shortread_qc (1)
Nov-21 14:37:38.851 [Task submitter] DEBUG nextflow.executor.GridTaskHandler - [PBSPRO] submitted process longread_qc (2) > jobId: 101965083.gadi-pbs; workDir: /g/data/xl04/ka6418/github/ausarg/work/00/1570032c9da1972bddbe60012c6d6f
Nov-21 14:37:38.851 [Task submitter] INFO  nextflow.Session - [00/157003] Submitted process > longread_qc (2)
Nov-21 14:37:39.448 [Task submitter] DEBUG nextflow.executor.GridTaskHandler - [PBSPRO] submitted process longread_qc (1) > jobId: 101965087.gadi-pbs; workDir: /g/data/xl04/ka6418/github/ausarg/work/bb/c7a83d9e7130145117dad18f72c46d
Nov-21 14:37:39.448 [Task submitter] INFO  nextflow.Session - [bb/c7a83d] Submitted process > longread_qc (1)
Nov-21 14:38:28.338 [Task monitor] DEBUG n.processor.TaskPollingMonitor - Task completed > TaskHandler[jobId: 101965080.gadi-pbs; id: 2; name: shortread_qc (1); status: COMPLETED; exit: 1; error: -; workDir: /g/data/xl04/ka6418/github/ausarg/work/58/9654eb751d4a736a214e5e22524c2e started: 1700541508331; exited: 2023-11-21T04:38:27Z; ]
Nov-21 14:38:28.349 [Task monitor] DEBUG nextflow.processor.TaskProcessor - Handling unexpected condition for
  task: name=shortread_qc (1); work-dir=/g/data/xl04/ka6418/github/ausarg/work/58/9654eb751d4a736a214e5e22524c2e
  error [nextflow.exception.ProcessFailedException]: Process `shortread_qc (1)` terminated with an error exit status (1)
Nov-21 14:38:28.381 [Task monitor] ERROR nextflow.processor.TaskProcessor - Error executing process > 'shortread_qc (1)'

Caused by:
  Process `shortread_qc (1)` terminated with an error exit status (1)

Command executed:

  #!/usr/bin/env python
  import csv
  import gzip
  from collections import defaultdict
  import hashlib
  import argparse
  import os
  import json
  from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor
  
  def phred_to_quality(phred_string):
  
      return [ord(char) - 33 for char in phred_string]
  
  def get_file_size_gb(file_path):
  
      size_in_bytes = os.path.getsize(file_path)
      size_in_gb = size_in_bytes / (1024 ** 2)  # Corrected to return in GB
      return round(size_in_gb, 2)
  
  def calculate_md5_compressed(fastq_file):
      hash_md5_compressed = hashlib.md5()
      with open(fastq_file, 'rb') as f:
          for chunk in iter(lambda: f.read(4096), b""):
              hash_md5_compressed.update(chunk)
      return hash_md5_compressed.hexdigest()
  
  def calculate_md5_uncompressed(fastq_file):
      hash_md5_uncompressed = hashlib.md5()
      with gzip.open(fastq_file, 'rt') as f:
          for line in f:
              hash_md5_uncompressed.update(line.encode())
      return hash_md5_uncompressed.hexdigest()
  
  def parse_fastq(fastq_file):
  
      num_reads = 0
      total_bases = 0
      quality_scores_sum = defaultdict(int)
      quality_scores_count = defaultdict(int)
      total_bases_count = defaultdict(int)
      avg_qv_reads = [0] * 101
      total_gc_count = 0
      nucleotide_freq_data = defaultdict(lambda: defaultdict(int))
      overall_content_data = defaultdict(int)
      BASES_ORDER = ['A', 'C', 'G', 'T', 'N']
      bases = set()
      with gzip.open(fastq_file, 'rt') as f:
          for i, line in enumerate(f):
              # Sequence lines are the second line in every set of 4 lines
              if i % 4 == 1:
                  seq = line.strip()
                  num_reads += 1
                  total_bases += len(seq)
                  total_gc_count += seq.count('G') + seq.count('C')
                  for idx, base in enumerate(seq):
                      total_bases_count[idx] += 1
                      nucleotide_freq_data[idx][base] += 1
                      overall_content_data[base] += 1
                      bases.update(base)
              elif i % 4 == 3:
                  qs = line.strip()
                  scores = phred_to_quality(qs)
                  avg_quality = sum(scores) / len(scores) if scores else 0
                  bin_index = min(int(avg_quality), 100)
                  avg_qv_reads[bin_index] += 1
                  for idx, score in enumerate(scores):
                      quality_scores_sum[idx] += score
                      quality_scores_count[idx] += 1
  
      avg_quality_values = [round(quality_scores_sum[i] / quality_scores_count[i]) if quality_scores_count[i] != 0 else 0 for i in range(len(quality_scores_sum))]
      gc_content = round((total_gc_count / total_bases) * 100, 2) if total_bases else 0
      nucleotide_freq = [":".join(str(nucleotide_freq_data[idx].get(base, 0)) for base in BASES_ORDER) for idx in nucleotide_freq_data]
      overall_content = ":".join(str(overall_content_data.get(base, 0)) for base in BASES_ORDER)
  
      with ThreadPoolExecutor() as executor:
          future_md5_compressed = executor.submit(calculate_md5_compressed, fastq_file)
          future_md5_uncompressed = executor.submit(calculate_md5_uncompressed, fastq_file)
          md5_compressed = future_md5_compressed.result()
          md5_uncompressed = future_md5_uncompressed.result()
  
      return {
          'num_reads': num_reads,
          'total_bases': total_bases,
          'avg_read_length': total_bases / num_reads if num_reads > 0 else 0,
          'avg_quality_values': avg_quality_values,
          'gc_content': gc_content,
          'md5_compressed': md5_compressed,
          'md5_uncompressed': md5_uncompressed,
          'avg_qv_reads': avg_qv_reads,
          'file_size_gb': get_file_size_gb(fastq_file),
          'path': os.path.abspath(fastq_file),
          'nucleotide_freq': nucleotide_freq,
          'overall_content': overall_content
      }
  
  def main():
  
  
      metrics = []
      fastq_files = ['test_illum_R1.fastq.gz','test_illum_R2.fastq.gz']
  
      num_cores_per_file = 2 // len(fastq_files)
  
      with ProcessPoolExecutor(max_workers=num_cores_per_file) as executor:
          for result in executor.map(parse_fastq, fastq_files):
              metrics.append(result)
  
      headers = [
          'File_path','Sample','Flowcell','Number_of_reads', 'Number_of_bases', 'Mean_read_length',
          'Mean_QV_at_read_position', 'Nucleotide_count_at_read_position',
          'Nucleotide_content', 'Mean_QV_per_read',
          'MD5_zipped', 'MD5_text', 'GC', 'File_size_in_MB'
      ]
  
      combined_metrics = []
      keys = [
          'path','PILRUE','maf758','num_reads', 'total_bases', 'avg_read_length', 'avg_quality_values',
          'nucleotide_freq', 'overall_content', 'avg_qv_reads', 'md5_compressed',
          'md5_uncompressed', 'gc_content', 'file_size_gb'
      ]
  
      for key in keys:
          if isinstance(metrics[0][key], list):
              combined_val = ",".join(str(val) for val in metrics[0][key])
              if len(metrics) > 1:
                  combined_val += ";" + ",".join(str(val) for val in metrics[1][key])
          else:
              combined_val = f"{metrics[0][key]}"
              if len(metrics) > 1:
                  combined_val += f";{metrics[1][key]}"
          combined_metrics.append(combined_val)
  
      metrics_dict = dict(zip(headers, combined_metrics))
  
  
      with open(os.path.join('shortread_qc', f"{'PILRUE'}_{'maf758'}_{'ILLUMINA'}.csv"), 'w', newline='') as csvfile:
          csvwriter = csv.writer(csvfile)
          csvwriter.writerow(headers)
          csvwriter.writerow(combined_metrics)
  
  
  
  if __name__ == "__main__":
      main()

Command exit status:
  1

Command output:
  (empty)

Command error:
  Traceback (most recent call last):
    File ".command.sh", line 145, in <module>
      main()
    File ".command.sh", line 124, in main
      if isinstance(metrics[0][key], list):
  KeyError: 'PILRUE'

Work dir:
  /g/data/xl04/ka6418/github/ausarg/work/58/9654eb751d4a736a214e5e22524c2e

Tip: you can replicate the issue by changing to the process work dir and entering the command `bash .command.run`
Nov-21 14:38:28.386 [Task monitor] DEBUG nextflow.Session - Session aborted -- Cause: Process `shortread_qc (1)` terminated with an error exit status (1)
Nov-21 14:38:28.400 [main] DEBUG nextflow.Session - Session await > all processes finished
Nov-21 14:38:28.400 [main] DEBUG nextflow.Session - Session await > all barriers passed
Nov-21 14:38:28.412 [main] WARN  n.processor.TaskPollingMonitor - Killing running tasks (2)
Nov-21 14:38:29.071 [main] DEBUG nextflow.trace.WorkflowStatsObserver - Workflow completed > WorkflowStats[succeededCount=0; failedCount=1; ignoredCount=0; cachedCount=0; pendingCount=0; submittedCount=1; runningCount=-1; retriesCount=0; abortedCount=2; succeedDuration=0ms; failedDuration=7ms; cachedDuration=0ms;loadCpus=-1; loadMemory=0; peakRunning=1; peakCpus=1; peakMemory=0; ]
Nov-21 14:38:29.087 [main] DEBUG nextflow.cache.CacheDB - Closing CacheDB done
Nov-21 14:38:29.088 [main] INFO  org.pf4j.AbstractPluginManager - Stop plugin 'nf-sqldb@0.5.0'
Nov-21 14:38:29.088 [main] DEBUG nextflow.plugin.BasePlugin - Plugin stopped nf-sqldb
Nov-21 14:38:29.114 [main] DEBUG nextflow.script.ScriptRunner - > Execution complete -- Goodbye
